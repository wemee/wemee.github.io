---
title: "ä¸‹æ¨“æ¢¯ RLï¼šå¾è¦å‰‡ AI å¤±æ•—åˆ°å¼·åŒ–å­¸ç¿’æˆåŠŸçš„æ¶æ§‹å¯¦è¸"
pubDate: 2026-01-14
description: "è¨˜éŒ„ä¸‹æ¨“æ¢¯éŠæˆ²å¾è¦å‰‡ AI å¤±æ•—åˆ° RL æˆåŠŸçš„å®Œæ•´æ­·ç¨‹ã€‚æ¢è¨ GameCore åˆ†é›¢ã€PyMiniRacer æ•¸å€¼ä¸€è‡´æ€§ã€çµ±ä¸€è¨“ç·´æ¡†æ¶èˆ‡ 500K æ­¥è¨“ç·´çš„å¯¦ä½œç´°ç¯€ã€‚"
author: "wemee (with AI assistant)"
tags: ["reinforcement-learning", "ppo", "architecture", "pytorch", "tensorflow-js", "solid"]
---

## å‰è¨€ï¼šå¤±æ•—ä¹‹å¾Œ

åœ¨[ä¸Šä¸€ç¯‡æ–‡ç« ](/blog/stairs-ai-failure)ä¸­ï¼Œæˆ‘è¨˜éŒ„äº†ä½¿ç”¨è¦å‰‡ AI çš„æ…˜ç—›å¤±æ•—ã€‚éœ‡ç›ªæ•ˆæ‡‰ã€é–å®šæ©Ÿåˆ¶çš„é›™é¢åˆƒã€è²ªå©ªæ¼”ç®—æ³•çš„ä¾·é™â€”â€”é€™äº›å•é¡Œè®“æˆ‘æ„è­˜åˆ°ï¼š**æ‰‹å·¥æ‰“é€ çš„æ±ºç­–æ¨¹ç„¡æ³•æ‡‰å°é«˜å‹•æ…‹ç’°å¢ƒ**ã€‚

é€™æ¬¡ï¼Œæˆ‘æ±ºå®šå¯¦è¸ä¹‹å‰çš„çµè«–ï¼š**å¼•å…¥å¼·åŒ–å­¸ç¿’ (Reinforcement Learning)**ã€‚

ä½† RL ä¸åªæ˜¯ã€Œæ›å€‹æ¼”ç®—æ³•ã€é€™éº¼ç°¡å–®ã€‚å®ƒç‰½æ¶‰åˆ°æ¶æ§‹é‡æ§‹ã€æ•¸å€¼ä¸€è‡´æ€§ä¿è­‰ã€è¨“ç·´æ¡†æ¶è¨­è¨ˆç­‰ä¸€ç³»åˆ—å·¥ç¨‹æŒ‘æˆ°ã€‚é€™ç¯‡æ–‡ç« è¨˜éŒ„äº†å¾é›¶åˆ°æœ‰çš„å®Œæ•´å¯¦è¸éç¨‹ã€‚

â†’ **[ç«‹å³è©¦ç© RL AI](/game/stairs)** â†

## æ ¸å¿ƒæŒ‘æˆ°ï¼šæ¶æ§‹è¨­è¨ˆ

è¦è¨“ç·´ RL æ¨¡å‹ï¼Œé¦–å…ˆè¦è§£æ±ºä¸€å€‹æ ¹æœ¬å•é¡Œï¼š

> **å¦‚ä½•è®“ Python è¨“ç·´ç’°å¢ƒèˆ‡ç€è¦½å™¨éŠæˆ²ä¿æŒ 100% ä¸€è‡´ï¼Ÿ**

### æŒ‘æˆ° 1ï¼šé‚è¼¯èˆ‡æ¸²æŸ“è€¦åˆ

æœ€åˆçš„ `StairsGame.ts` æ˜¯ä¸€å€‹å…¸å‹çš„å–®é«”é¡åˆ¥ï¼š

```typescript
export class StairsGame {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;
  private player = { x: 200, y: 300, vx: 0, vy: 0 };
  private stairs: Stair[] = [];

  private update() {
    // ç‰©ç†æ›´æ–°
    this.player.vy += 0.3;  // é‡åŠ›
    this.player.y += this.player.vy;

    // æ¸²æŸ“
    this.ctx.fillRect(this.player.x, this.player.y, 30, 30);
  }
}
```

é€™æ¨£çš„æ¶æ§‹ç„¡æ³•åœ¨ Python ä¸­é‹è¡Œï¼ˆæ²’æœ‰ Canvasï¼‰ï¼Œä¹Ÿç„¡æ³•ä¿è­‰è¨“ç·´æ™‚çš„ç‰©ç†è¨ˆç®—èˆ‡ç€è¦½å™¨å®Œå…¨ç›¸åŒã€‚

### è§£æ±ºæ–¹æ¡ˆï¼šGameCore æŠ½è±¡å±¤

åƒè€ƒ OpenAI Gym/Gymnasium æ¨™æº–ï¼Œæˆ‘è¨­è¨ˆäº†ä¸€å€‹**ç´”é‚è¼¯çš„ GameCore**ï¼š

```typescript
// src/lib/games/core/GameCore.ts
export abstract class GameCore<TObservation, TAction> {
  abstract reset(): TObservation;
  abstract step(action: TAction): StepResult<TObservation>;
  abstract getState(): TObservation;
}

// src/lib/games/StairsGameCore.ts
export class StairsGameCore extends GameCore<StairsGameState, Action> {
  // ç´”é‚è¼¯ï¼Œç„¡ DOM ä¾è³´
  step(action: Action): StepResult<StairsGameState> {
    // ç‰©ç†æ›´æ–°
    this.player.vy += this.GRAVITY;

    // ç¢°æ’æª¢æ¸¬
    const collision = this.checkCollision();

    // çå‹µè¨ˆç®—
    const reward = this.calculateReward();

    return {
      observation: this.getState(),
      reward,
      terminated: this.gameOver,
      truncated: false
    };
  }
}
```

ç„¶å¾Œè®“ç€è¦½å™¨ç‰ˆæœ¬**å§”è¨—é‚è¼¯çµ¦ Core**ï¼š

```typescript
// src/lib/games/StairsGame.ts
export class StairsGame {
  private core: StairsGameCore;  // å§”è¨—é‚è¼¯

  private update() {
    const action = this.getUserInput();
    const result = this.core.step(action);  // ä½¿ç”¨ Core
    this.render(result.observation);  // åªè² è²¬æ¸²æŸ“
  }
}
```

é€™æ¨£åšçš„å¥½è™•ï¼š
- âœ… **å–®ä¸€æ•¸æ“šä¾†æº** (Single Source of Truth)
- âœ… **é‚è¼¯èˆ‡æ¸²æŸ“åˆ†é›¢** (Separation of Concerns)
- âœ… **å¯æ¸¬è©¦æ€§** (Testability) - Core å¯ç¨ç«‹æ¸¬è©¦

## æŒ‘æˆ° 2ï¼šPython å¦‚ä½•åŸ·è¡Œ TypeScriptï¼Ÿ

GameCore æ˜¯ç”¨ TypeScript å¯«çš„ï¼Œä½†è¨“ç·´ç’°å¢ƒéœ€è¦ Pythonã€‚æœ‰å¹¾ç¨®é¸æ“‡ï¼š

| æ–¹æ¡ˆ | å„ªé» | ç¼ºé» |
|------|------|------|
| é‡å¯« Python ç‰ˆæœ¬ | ç°¡å–® | âŒ ç¶­è­·å…©ä»½ä»£ç¢¼ï¼Œæ•¸å€¼å¯èƒ½ä¸ä¸€è‡´ |
| ä½¿ç”¨ Node.js é€²ç¨‹é€šä¿¡ | åŸç”Ÿæ”¯æ´ | âŒ IPC é–‹éŠ·å¤§ï¼Œè¨“ç·´æ…¢ |
| **PyMiniRacer (V8)** | âœ… åœ¨ Python ä¸­åŸ·è¡ŒçœŸå¯¦ JS | âœ… 100% æ•¸å€¼ä¸€è‡´ |

æˆ‘é¸æ“‡ **PyMiniRacer**ï¼Œå®ƒåœ¨ Python ä¸­åµŒå…¥ V8 JavaScript å¼•æ“ï¼š

```python
from py_mini_racer import MiniRacer

ctx = MiniRacer()

# 1. è¼‰å…¥ç·¨è­¯å¥½çš„ GameCore.js (esbuild IIFE æ ¼å¼)
ctx.eval(open('dist/StairsGameCore.js').read())

# 2. è§£åŒ… IIFE å…¨åŸŸè®Šæ•¸
ctx.eval("const StairsGameCoreClass = StairsGameCore.StairsGameCore;")
ctx.eval("const game = new StairsGameCoreClass();")

# 3. åŸ·è¡ŒéŠæˆ²é‚è¼¯
state_json = ctx.eval("JSON.stringify(game.reset())")
state = json.loads(state_json)  # è½‰æˆ Python dict
```

### é—œéµï¼šJSON åºåˆ—åŒ–

MiniRacer è¿”å›çš„æ˜¯ JavaScript å°è±¡ï¼ˆ`JSMappedObjectImpl`ï¼‰ï¼Œç„¡æ³•ç›´æ¥åœ¨ Python ä¸­æ“ä½œã€‚è§£æ±ºæ–¹æ³•ï¼š

```python
def _get_state_dict(self):
    """é€é JSON åºåˆ—åŒ–é¿å…å°è±¡é¡å‹å•é¡Œ"""
    state_json = self.ctx.eval("JSON.stringify(game.getState())")
    return json.loads(state_json)  # ç´” Python dict
```

é€™æ¨£ç¢ºä¿äº†ï¼š
- âœ… **100% æ•¸å€¼ä¸€è‡´æ€§** - ä½¿ç”¨åŒä¸€ä»½ JS ä»£ç¢¼
- âœ… **IEEE 754 æ¨™æº–** - V8 èˆ‡ç€è¦½å™¨éƒ½æ˜¯ double precision
- âœ… **ç¶­è­·æ€§** - åªéœ€ç¶­è­·ä¸€ä»½ TypeScript ä»£ç¢¼

## æŒ‘æˆ° 3ï¼šçµ±ä¸€è¨“ç·´æ¡†æ¶

æœ‰äº† GameCore å’Œ PyMiniRacerï¼Œæ¥ä¸‹ä¾†è¦å»ºç«‹ Gymnasium ç’°å¢ƒï¼š

```python
# ml-training/stairs-rl/stairs_env.py
import gymnasium as gym
from gymnasium import spaces

class StairsEnv(gym.Env):
    def __init__(self):
        self.ctx = MiniRacer()
        self.ctx.eval(open('dist/StairsGameCore.js').read())
        self.ctx.eval("const game = new StairsGameCore.StairsGameCore();")

        # å®šç¾©å‹•ä½œç©ºé–“ï¼šleft, right, none
        self.action_space = spaces.Discrete(3)

        # å®šç¾©è§€å¯Ÿç©ºé–“ï¼šplayer(4) + stairs(10*5) = 54 ç¶­
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(54,), dtype=np.float32
        )

    def reset(self, seed=None, options=None):
        state_json = self.ctx.eval("JSON.stringify(game.reset())")
        state = json.loads(state_json)
        return self._get_obs(state), {}

    def step(self, action):
        action_str = ['left', 'right', 'none'][action]
        result_json = self.ctx.eval(f"JSON.stringify(game.step('{action_str}'))")
        result = json.loads(result_json)

        obs = self._get_obs(result['observation'])
        reward = result['reward']
        terminated = result['terminated']
        truncated = result['truncated']

        return obs, reward, terminated, truncated, {}

    def _get_obs(self, state):
        """å°‡ JS state ç·¨ç¢¼ç‚º 54 ç¶­å‘é‡"""
        obs = np.zeros(54, dtype=np.float32)

        # Player (4 dims)
        obs[0] = state['player']['x'] / 400.0
        obs[1] = state['player']['y'] / 600.0
        obs[2] = state['player']['vx'] / 10.0
        obs[3] = state['player']['vy'] / 20.0

        # Stairs (10 stairs * 5 features)
        for i, stair in enumerate(state['stairs'][:10]):
            base = 4 + i * 5
            obs[base] = stair['x'] / 400.0
            obs[base + 1] = stair['y'] / 600.0
            obs[base + 2] = stair['width'] / 120.0
            obs[base + 3] = 1.0 if stair['broken'] else 0.0
            obs[base + 4] = {'normal': 0, 'bounce': 1, 'fragile': 2, 'moving': 3}[stair['type']] / 3.0

        return obs
```

### Template Method è¨“ç·´æ¡†æ¶

ç‚ºäº†è®“æœªä¾†çš„éŠæˆ²å¯ä»¥é‡ç”¨è¨“ç·´é‚è¼¯ï¼Œæˆ‘è¨­è¨ˆäº† `BaseRLTrainer`ï¼š

```python
# ml-training/shared/base_trainer.py
from abc import ABC, abstractmethod

class BaseRLTrainer(ABC):
    def __init__(self, env_id: str, output_dir: Path):
        self.env_id = env_id
        self.output_dir = output_dir

    @abstractmethod
    def create_model(self, env):
        """å­é¡å¯¦ä½œï¼šå»ºç«‹ RL æ¼”ç®—æ³• (PPO, DQN, etc.)"""
        pass

    @abstractmethod
    def export_tfjs(self, model_path, tfjs_path):
        """å­é¡å¯¦ä½œï¼šå°å‡ºç‚º TF.js æ ¼å¼"""
        pass

    def train(self, total_timesteps, n_envs, callbacks):
        """çµ±ä¸€è¨“ç·´æµç¨‹"""
        env = make_vec_env(self.env_id, n_envs=n_envs)
        self.model = self.create_model(env)
        self.model.learn(
            total_timesteps=total_timesteps,
            callback=callbacks,
            progress_bar=True
        )
        self.model.save(self.output_dir / 'models' / 'final_model')
        env.close()
```

å¯¦éš›è¨“ç·´æ™‚ï¼Œåªéœ€ç¹¼æ‰¿ä¸¦å¯¦ä½œå…©å€‹æ–¹æ³•ï¼š

```python
# ml-training/stairs-rl/train.py
class StairsRLTrainer(BaseRLTrainer):
    def create_model(self, env):
        return PPO(
            "MlpPolicy", env,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=64,
            gamma=0.99,
            verbose=1
        )

    def export_tfjs(self, model_path, tfjs_path):
        # ä½¿ç”¨ export_weights_json.py
        pass

trainer = StairsRLTrainer(env_id='Stairs-v0', output_dir='output')
trainer.train(total_timesteps=500_000, n_envs=4)
```

é€™æ¨£çš„è¨­è¨ˆç¬¦åˆ **SOLID åŸå‰‡**ï¼š
- **Open-Closed**: å°æ“´å±•é–‹æ”¾ï¼ˆæ–°éŠæˆ²ç¹¼æ‰¿ BaseRLTrainerï¼‰ï¼Œå°ä¿®æ”¹é—œé–‰
- **Template Method**: å®šç¾©è¨“ç·´æµç¨‹éª¨æ¶ï¼Œç´°ç¯€ç”±å­é¡å¯¦ä½œ

## è¨“ç·´çµæœ

ç¶“é 7 åˆ† 26 ç§’ï¼Œè¨“ç·´å®Œæˆï¼š

```
Total timesteps: 507,904 (è¶…éç›®æ¨™ 500K)
Training speed: ~1,138 steps/sec (4 parallel envs)
Final episode reward mean: 205

=== Final Evaluation (10 episodes) ===
Average score: 11.5 (Â±6.5)
Best episode: 28 points, 837 steps, reward=585.0
Score range: 4-28 points
```

### è¨“ç·´æ›²ç·šåˆ†æ

```
  8K steps: ep_rew_mean = 79.6   (åˆå§‹éš¨æ©Ÿæ¢ç´¢)
160K steps: ep_rew_mean = 153    (é–‹å§‹å­¸æœƒåŸºæœ¬ç”Ÿå­˜)
320K steps: ep_rew_mean = 226    (æ€§èƒ½å³°å€¼)
500K steps: ep_rew_mean = 205    (ç©©å®šæ”¶æ–‚)
```

æ¨¡å‹åœ¨ 32 è¬æ­¥é”åˆ°å³°å€¼å¾Œç•¥å¾®ä¸‹é™ï¼Œé€™æ˜¯ RL ä¸­å¸¸è¦‹çš„**æ¢ç´¢-åˆ©ç”¨æ¬Šè¡¡** (Exploration-Exploitation Tradeoff)ã€‚

### æ¨¡å‹ä¸€è‡´æ€§é©—è­‰

åœ¨å°å‡ºæ¨¡å‹æ¬Šé‡æ™‚ï¼Œæˆ‘é©—è­‰äº† PyTorch (è¨“ç·´) èˆ‡ TensorFlow (æ¨ç†) çš„ä¸€è‡´æ€§ï¼š

```python
# æ¸¬è©¦ 10 å€‹éš¨æ©Ÿè§€å¯Ÿ
Max difference: 1.19e-07

âœ“ æ¨¡å‹ä¸€è‡´æ€§é©—è­‰é€šéï¼
```

èª¤å·®å°æ–¼ **åå„„åˆ†ä¹‹ä¸€**ï¼Œå¯ä»¥æ”¾å¿ƒéƒ¨ç½²åˆ°ç€è¦½å™¨ã€‚

## æŒ‘æˆ° 4ï¼šæ¨¡å‹å°å‡ºèˆ‡éƒ¨ç½²

æœ€åˆæˆ‘å˜—è©¦ä½¿ç”¨ `tensorflowjs_converter`ï¼Œä½†é‡åˆ°ä¾è³´è¡çªï¼š

```bash
ERROR: Cannot install tensorflowjs==4.22.0 because these package
versions have conflicting dependencies.
```

### è§£æ±ºæ–¹æ¡ˆï¼šJSON æ¬Šé‡å°å‡º

èˆ‡å…¶ç³¾çµè¤‡é›œçš„è½‰æ›å·¥å…·ï¼Œæˆ‘é¸æ“‡äº†æœ€ç°¡å–®çš„æ–¹æ³•ï¼š**ç›´æ¥å°å‡ºæ¬Šé‡ç‚º JSON**ã€‚

```python
# ml-training/stairs-rl/export_weights_json.py
def extract_weights_as_json(model):
    policy_net = model.policy.mlp_extractor.policy_net

    weights = {
        "model_info": {
            "architecture": "PPO Policy Network",
            "input_dim": 54,
            "hidden_dim": 64,
            "output_dim": 3
        },
        "weights": {
            "policy_layer1": {
                "kernel": policy_net[0].weight.T.tolist(),  # PyTorch (out,in) â†’ TF (in,out)
                "bias": policy_net[0].bias.tolist()
            },
            "policy_layer2": {
                "kernel": policy_net[2].weight.T.tolist(),
                "bias": policy_net[2].bias.tolist()
            },
            "action_logits": {
                "kernel": model.policy.action_net.weight.T.tolist(),
                "bias": model.policy.action_net.bias.tolist()
            }
        }
    }
    return weights
```

åœ¨ç€è¦½å™¨ä¸­ï¼Œæ‰‹å‹•æ§‹å»ºæ¨¡å‹ä¸¦è¼‰å…¥æ¬Šé‡ï¼š

```typescript
// src/lib/ai/agents/StairsWeightsAgent.ts
async load() {
  const response = await fetch('/models/stairs/model_weights.json');
  const data = await response.json();

  // æ§‹å»ºæ¨¡å‹çµæ§‹ï¼ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰
  this.model = tf.sequential({
    layers: [
      tf.layers.dense({units: 64, activation: 'tanh', inputShape: [54]}),
      tf.layers.dense({units: 64, activation: 'tanh'}),
      tf.layers.dense({units: 3, activation: 'softmax'})
    ]
  });

  // è¼‰å…¥æ¬Šé‡
  this.model.layers[0].setWeights([
    tf.tensor2d(data.weights.policy_layer1.kernel),
    tf.tensor1d(data.weights.policy_layer1.bias)
  ]);
  // ... å…¶ä»–å±¤
}
```

é€™ç¨®æ–¹æ³•çš„å„ªé»ï¼š
- âœ… **ç„¡ä¾è³´è¡çª** - ä¸éœ€è¦ tensorflowjs_converter
- âœ… **è¼•é‡åŒ–** - æ¬Šé‡æª”æ¡ˆåƒ… 245 KB
- âœ… **å®Œå…¨æ§åˆ¶** - æ¨¡å‹çµæ§‹ç”±æˆ‘å€‘å®šç¾©

## æ¶æ§‹ç¸½çµï¼šSOLID åŸå‰‡å¯¦è¸

é€™æ¬¡é‡æ§‹å®Œæ•´å¯¦è¸äº† SOLID äº”å¤§åŸå‰‡ï¼š

### 1. Single Responsibility (å–®ä¸€è·è²¬)
- `GameCore`: åªè² è²¬éŠæˆ²é‚è¼¯
- `Game`: åªè² è²¬æ¸²æŸ“èˆ‡ç”¨æˆ¶è¼¸å…¥
- `Agent`: åªè² è²¬ AI æ¨ç†

### 2. Open-Closed (é–‹é–‰åŸå‰‡)
- æ–°éŠæˆ²åªéœ€ç¹¼æ‰¿ `GameCore`ï¼Œç„¡éœ€ä¿®æ”¹åŸºé¡
- æ–° AI åªéœ€ç¹¼æ‰¿ `TFJSAgent`ï¼Œç„¡éœ€ä¿®æ”¹æ¡†æ¶

### 3. Liskov Substitution (é‡Œæ°æ›¿æ›)
- æ‰€æœ‰ `GameCore` å­é¡å¯äº’æ›ä½¿ç”¨
- æ‰€æœ‰ `Agent` å­é¡éµå¾ªç›¸åŒæ¥å£

### 4. Interface Segregation (æ¥å£éš”é›¢)
- `Agent` æ¥å£æœ€å°åŒ–ï¼š`load()`, `predict()`, `destroy()`
- `GameCore` æ¥å£æœ€å°åŒ–ï¼š`reset()`, `step()`, `getState()`

### 5. Dependency Inversion (ä¾è³´åè½‰)
- `Game` ä¾è³´æŠ½è±¡çš„ `GameCore`ï¼Œè€Œéå…·é«”å¯¦ä½œ
- `Trainer` ä¾è³´æŠ½è±¡çš„ `gym.Env`ï¼Œè€Œéå…·é«”éŠæˆ²

## æŠ€è¡“æ£§ç¸½çµ

```
Frontend (Browser)
â”œâ”€â”€ TypeScript/Astro
â”œâ”€â”€ TensorFlow.js 4.22.0
â””â”€â”€ Canvas API

Training (Python)
â”œâ”€â”€ PyMiniRacer 0.12.0 (V8 å¼•æ“)
â”œâ”€â”€ Stable Baselines3 2.2.0 (PPO)
â”œâ”€â”€ Gymnasium 0.29.0
â””â”€â”€ PyTorch 2.0.0

Build Tools
â”œâ”€â”€ esbuild (TS â†’ JS)
â””â”€â”€ npm scripts
```

## æœªä¾†å±•æœ›

é€™å¥—æ¶æ§‹å·²ç¶“å¯ä»¥è¼•é¬†æ“´å±•åˆ°å…¶ä»–éŠæˆ²ï¼š

1. **Breakout RL** - æ‰“ç£šå¡Šçš„ RL ç‰ˆæœ¬
2. **å¤šæ™ºèƒ½é«”è¨“ç·´** - è®“å…©å€‹ AI å°æˆ°
3. **Curriculum Learning** - å¾ç°¡å–®é—œå¡é€æ­¥å¢åŠ é›£åº¦

æ›´é‡è¦çš„æ˜¯ï¼Œé€™æ¬¡å¯¦è¸è­‰æ˜äº†ï¼š

> **å¥½çš„æ¶æ§‹è¨­è¨ˆï¼Œè®“è¤‡é›œçš„ AI ç³»çµ±è®Šå¾—å¯ç¶­è­·ã€å¯æ“´å±•ã€å¯æ¸¬è©¦ã€‚**

## å»¶ä¼¸é–±è®€

- [ä¸‹æ¨“æ¢¯éŠæˆ² AIï¼šå¾è¦å‰‡å¼•æ“åˆ°æ§åˆ¶ç†è«–çš„å¤±æ•—å¯¦é©—](/blog/stairs-ai-failure)
- [æ‰“ç£šå¡ŠéŠæˆ² AIï¼šç‰©ç†æ¨¡æ“¬èˆ‡è»Œè·¡é æ¸¬](/blog/breakout-ai)
- [åœ¨ç€è¦½å™¨ä¸­è¨“ç·´ MNISTï¼šTensorFlow.js å¯¦æˆ°](/blog/mnist-browser-ml)

---

**è©¦ç©å¼·åŒ–å­¸ç¿’ AIï¼š** å‰å¾€ [ä¸‹æ¨“æ¢¯éŠæˆ²é é¢](/game/stairs)ï¼Œé»æ“Šã€ŒğŸ§  å¼·åŒ–å­¸ç¿’ AIã€æŒ‰éˆ•é«”é©—è¨“ç·´æˆæœï¼

---

*æœ¬æ–‡ç”± wemee èˆ‡ AI åŠ©æ‰‹ Claude å…±åŒå®Œæˆã€‚è¨˜éŒ„çœŸå¯¦çš„å·¥ç¨‹å¯¦è¸èˆ‡æ€è€ƒéç¨‹ã€‚*
